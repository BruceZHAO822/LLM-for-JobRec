## 研究领域现状

大型语言模型(LLMs)在自然语言处理领域展现出强大能力，近期在推荐系统领域获得了显著关注。这些通过自监督学习训练的模型在学习通用表示方面表现出色，通过微调、提示调整等转移技术增强了推荐系统的各方面性能。

## 研究领域痛点

1. 模型偏见问题：位置偏见、流行度偏见、公平性偏见和个性化偏见
2. 推荐提示设计挑战：用户/物品表示不足、上下文长度限制
3. 生成控制困难：输出难以控制，难以保证与指令格式一致
4. 评估标准不完善：缺乏适用于生成式推荐系统的评估指标
5. 数据集局限性：现有数据集相对较小，可能无法全面评估LLMs的推荐能力

## 主要方法

作者将基于LLM的推荐系统分为两大范式：

1. 判别式LLM推荐(DLLM4Rec)
2. 生成式LLM推荐(GLLM4Rec)

并详细梳理了LLM在推荐系统中的适应策略，包括微调、提示学习、提示调优和指令调优等技术。

## 创新点

1. 首次系统全面地回顾了专门针对生成式LLM的推荐系统相关研究
2. 提出了基于LLM的推荐系统的分类框架
3. 明确定义并区分了微调、提示学习、提示调优和指令调优在LLM推荐中的应用
4. 总结了现有研究的共同发现和挑战

## 评估指标

文章讨论了多种评估指标，包括传统推荐系统的指标(如NDCG、MSE等)以及针对生成式推荐的新指标，如连贯性、相关性、多样性和新颖性。

## 实验结果及结论

1. LLM展现出令人印象深刻的零样本/少样本推荐能力
2. LLM具有强大的可解释能力，即使在上下文学习设置中未经微调，ChatGPT仍优于传统监督方法
3. 当计算能力不断提高和人工智能领域扩展时，LLM在推荐系统中的应用将更加精细
4. 未来LLM可能在更多样化的领域中被利用，可能导致实时、个性化推荐
