### **研究领域现状**

1. **传统方法**：
   - **基于物品的协同过滤（Item-KNN）**：依赖物品共现或转移概率，仅考虑最后点击物品，忽略序列信息。
   - **矩阵分解（MF）**：需用户画像，不适用于匿名会话场景。
   - **马尔可夫决策过程（MDP）**：状态空间爆炸问题难以处理长序列。
2. **局限性**：
   - 无法建模**会话内时序依赖**（如用户点击序列的上下文）。
   - 匿名用户场景下，无法利用历史行为，导致推荐非个性化。

------

### **研究领域痛点**

1. **序列信息利用不足**：传统方法仅基于最后点击物品推荐，忽略用户行为序列的动态变化。
2. **匿名用户挑战**：无法建立长期用户画像，需仅依赖当前会话数据。
3. **计算效率问题**：物品库规模大（万级至百万级），传统方法难以实时处理。

------

### **核心方法**

1. **GRU（门控循环单元）建模**：
   - 输入：会话点击序列（1-of-N编码），输出：下一物品预测概率。
2. **会话并行小批量（Session-Parallel Mini-Batches）**：
   - **设计动机**：会话长度差异大，传统滑动窗口不适用。
   - **实现**：按会话顺序分批次，独立处理每个会话的隐藏状态。
3. **输出采样与排名损失**：
   - **负采样策略**：基于物品流行度采样，减少计算开销。
   - **损失函数**：
     - **BPR（贝叶斯个性化排序）**：最大化正样本与负样本得分差异。
     - **TOP1（作者提出）**：正则化损失，强制负样本得分趋近零。

------

### **创新点**

1. **首次引入RNN至会话推荐**：动态捕捉用户点击序列的时序依赖，超越传统静态方法。
2. **高效计算设计**：
   - 会话并行小批量提升训练效率，适配大规模数据。
   - 负采样与排名损失降低计算复杂度（从 O(N)*O*(*N*) 到 O(k)*O*(*k*)，k≪N*k*≪*N*）。
3. **TOP1损失函数**：解决传统交叉熵的不稳定性，提升模型收敛性与推荐效果。

------

### **评估指标与实验**

1. **指标**：
   - **Recall@20**：目标物品是否在前20推荐中（衡量覆盖率）。
   - **MRR@20**：目标物品排名的倒数均值（衡量排序质量）。
2. **实验结果**：
   - **数据集**：RSC15（电商点击流）、VIDEO（视频观看记录）。
   - **对比基线**：Item-KNN、POP、BPR-MF等。
   - **关键结果**：
     - **RSC15**：GRU（1000隐藏单元 + TOP1损失）Recall@20=62.06%（较Item-KNN提升22.53%）。
     - **VIDEO**：GRU（1000隐藏单元 + TOP1损失）Recall@20=66.24%（较Item-KNN提升20.27%）。
3. **效率**：
   - GPU训练耗时数小时（Titan X），适合实时更新场景。
