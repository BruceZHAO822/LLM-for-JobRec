- 研究领域现状:
  - 会话推荐 (SBR) 旨在基于用户当前匿名会话中的行为序列预测下一个交互项目。
  - 早期方法依赖马尔可夫链 (FPMC) 等序列模型。
  - 深度学习方法主导，包括：
    - **RNN-based:** 如 GRU4REC, NARM, STAMP，将会话视为严格有序序列，利用 RNN (如 GRU, LSTM) 或注意力机制捕捉时序依赖和用户意图变化。
    - **GNN-based:** 如 SR-GNN, FGNN, GC-SAN，将会话数据构建成图（通常是简单图），利用 GNN 聚合信息，捕捉项目间的转换关系（通常是成对关系）。
- 研究领域痛点:
  - **忽略高阶关系:** 现有模型（特别是 GNN）主要关注项目间的 *成对关系 (pairwise relations)* 或严格的 *时序依赖*，但现实中用户的选择往往受会话中 *多个* 先前项目共同影响，存在复杂的 *高阶关系 (high-order correlations)* 或 *集合式/连贯性关系 (set-like relations/coherence)*。
  - **简单图表达能力不足:** 传统图结构难以有效表示这种超越成对关系的复杂依赖。
  - **RNN 假设限制:** 严格的时序假设可能与用户行为不符（如随机播放列表），且可能忽略项目本身的内在关联性，易过拟合。
  - **GNN 提升有限:** GNN 方法虽有改进，但相比 RNN 提升幅度不大 (*trivial improvements*)，原因可能在于仍局限于建模成对关系。
  - **数据稀疏性:** 会话通常较短，包含项目有限，这可能限制了模型（尤其是超图模型）从有限数据中学习有效表示的能力 (*inherent data sparsity issue*)。
- 主要方法:提出**双通道超图卷积网络** (DHCN - Dual Channel Hypergraph Convolutional Network)
  1. 超图构建:
     - 将会话数据建模为超图 `G = (V, E)`。`V` 是所有唯一项目的集合（节点），`E` 是所有会话的集合，每个会话 `s = [i_1, i_2, ..., i_m]` 构成一个超边 `e ∈ E`，连接其包含的所有项目节点。
     - 这种构建方式天然地捕捉了会话内所有项目间的共同出现关系，即高阶关系。
  2. 超图通道 (Hypergraph Channel):
     - 在上述超图上应用超图卷积网络 (HCN)。采用简化的谱卷积形式 (`X^(l+1)_h = D^-1 H W B^-1 H^T X^(l)_h`)，进行节点-超边-节点的信息传递与聚合，捕捉项目级别的高阶相关性。`H` 是超图关联矩阵，`D`, `B` 是节点和超边的度矩阵。
     - 堆叠 L 层 HCN，并将各层输出平均得到最终项目嵌入 `X_h`。
     - 为保留部分时序信息，引入 **反向位置嵌入 (reversed position embeddings)** `P_r`，与项目嵌入 `X_h` 拼接后通过线性层和激活函数（tanh）得到带有时序信息项目表示 `x'_t`。
     - 采用 **软注意力机制 (soft-attention)** 聚合带有位置信息的项目嵌入，计算会话表示 `h`，作为当前会话的主要意图表示，用于预测。
  3. 线图通道 (Line Graph Channel):
     - 构建原始超图 `G` 的 **线图 (Line Graph) L(G)** 。线图的节点是原超图的超边（即会话），若两个会话（超边）在原超图中共享至少一个项目节点，则在线图中连接这两个会话节点。边的权重反映共享程度。
     - 在线图 L(G) 上应用标准图卷积网络 (GCN)，如 `Θ^(l+1)_l = D_hat^-1 A_hat Θ^(l)_l`，其中 `A_hat` 是线图的邻接矩阵（含自环），`D_hat` 是度矩阵。
     - 线图通道旨在学习 **会话级别 (session-level)** 的关系，即捕捉 **跨会话信息 (cross-session information)** 或会话间的连接性。
  4. 自监督学习 (Self-Supervised Learning):
     - 将超图通道得到的会话表示 `h`（聚合项目得到）和线图通道学习到的对应会话表示 `Θ_l`（直接学习的会话节点表示）视为同一会话的 **两个不同视图 (views)** 。
     - 采用 **对比学习 (Contrastive Learning)** 框架（基于 InfoNCE 损失）：对于一个小批量中的每个会话，最大化其在两个通道中表示的 **互信息 (Mutual Information)** ，即拉近同一会话的两个视图表示（正样本对），推远不同会话的表示（负样本对，通过 shuffling 构造）。
     - 损失函数 `L_s` 用于衡量两个视图表示的一致性。
     - 此自监督任务作为 **辅助任务 (auxiliary task)** ，与主推荐任务（基于 `h` 和目标项目嵌入计算的交叉熵损失 `L_r`）联合优化，总损失为 `L = L_r + β * L_s`，`β` 控制辅助任务的权重。目的是通过视图间信息互补，增强表示学习，尤其缓解稀疏性问题。
- 创新点:
  1. **首次应用超图卷积网络解决 SBR:** 明确使用超图结构来建模会话内项目的高阶依赖关系。
  2. **双通道架构:** 结合超图卷积（捕获会话内高阶关系）和基于线图的普通图卷积（捕获会话间关系），从不同粒度建模会话信息。
  3. **创新的自监督学习整合:** 将双通道学习到的表示作为不同视图，通过对比学习最大化互信息，作为辅助任务提升主推荐任务性能，并以此增强超图建模的效果，尤其是在数据稀疏场景下。
- 评估指标:
  - **P@K (Precision@K):** 推荐列表前 K 个项目中命中实际下一项的比例 (文中用 P@10, P@20)。
  - **MRR@K (Mean Reciprocal Rank@K):** 实际下一项在推荐列表前 K 个中的排名的倒数的平均值 (文中用 M@10, M@20)。
- 实验结果及结论:
  - **数据集:** Tmall, Nowplaying, Diginetica (均为公开基准数据集)。
  - **结果:** DHCN 及其自监督版本 S S ^2 -DHCN 在所有三个数据集上的 P@K 和 MRR@K 指标均显著优于所有基线模型 (Item-KNN, FPMC, GRU4REC, NARM, STAMP, SR-GNN, FGNN)，展现了“压倒性优势” (*overwhelming superiority*)。
  - 有效性验证:
    - 与 GNN 基线 (SR-GNN, FGNN) 的比较证明了超图建模捕捉高阶关系的有效性。
    - S S ^2 -DHCN 相较于 DHCN 的提升验证了自监督学习辅助任务的有效性，尤其在平均会话长度较短的数据集 (Nowplaying, Diginetica) 上提升更明显，说明有助于缓解数据稀疏问题。
